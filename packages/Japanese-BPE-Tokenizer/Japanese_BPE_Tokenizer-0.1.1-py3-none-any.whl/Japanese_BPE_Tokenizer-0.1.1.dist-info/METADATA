Metadata-Version: 2.1
Name: Japanese-BPE-Tokenizer
Version: 0.1.1
Summary: Mecab-based BPE toknizer for Japanese text
Home-page: http://github.com/stsuchi/Japanese-BPE-Tokenizer
Author: Shiro T.
License: MIT
Platform: UNKNOWN
Description-Content-Type: text/markdown
Requires-Dist: transformers
Requires-Dist: fugashi
Requires-Dist: unidic-lite

# Byte Pair Encoding for Japanese Language

## Summary
The package applies Mecab and Byte Pair Encoding algorithms to tokenize Japanese text.

## Usage
To train a new tokenizer, import the module
```
from train.implementations import MecabBPETrainTokenizer
```

Instantiate the object
```
tokenizer = MecabBPETrainTokenizer()
```

Set the arguments with the text, vocab_size and special_tokens to train the tokenizer
```
tokenizer.train(files,
                vocab_size=52000,
                special_tokens=["<pad>", "<unk>", "<s>", "</s>", "<mask>"])
```

And finally, save the trained config files
```
tokenizer.save_model('config')
```


