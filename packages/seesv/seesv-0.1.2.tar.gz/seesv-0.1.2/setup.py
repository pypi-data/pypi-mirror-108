# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['seesv']

package_data = \
{'': ['*']}

setup_kwargs = {
    'name': 'seesv',
    'version': '0.1.2',
    'description': 'A Python library providing fast access to data in very large delimited data files (CSV, TSV, pipe-delimited, etc).',
    'long_description': "# SeeSV\n\nSeeSV is a library for providing fast access to data in very large delimited data files (CSV, TSV, pipe-delimited, etc) as memory-efficient as possible.\n\nThis library grew out of the frustration of reading and analyzing very large (multi-gigabyte, 5+ million row) CSV files (and other delimited file formats). There are few options for reading these files to quickly find problems, generate a filtered subset, or find specific data. There was the constant need for both a command line tool that can be used on a server via an SSH terminal connection and a desktop tool that can quickly churn through huge files. There are many tools out there, but most fall flat when handling very large files - either they take forever to open the file or (and) end up crashing by running out of memory.\n\nThe goal with SeeSV is to provide both a re-usable library that encapsulates handling delimited files and a cross-platform desktop GUI that builds on top of the library to provide the user with the best possible experience and feature set.\n\nThis project provides the re-usable Python library that can be used to build tools or programmatically inspect files.\n\n\n\n## Design\n\n\n\n### SeeSV Features\n\n- Blazing fast loading of files so that the user gets to a productive state with the data within seconds.\n- Minimal memory consumption even for extremely large files.\n- The ability to jump to any area of a file in constant time, then provide a bounded or unbounded stream of parsed records from that point.\n- Handle files with or without headers, and files with extra header lines (like file summary metadata, etc).\n- Simple, intuitive API\n\n\n\n### Design\n\nWhen a file is opened, SeeSV performs a number of discovery tasks:\n\n1. Extract the column headers, if the file contains any. The headers are stored in a list accessible as a property of the DelimitedFile object.\n2. Scans the file to generate an internal index of the byte positions of the start of every line (row) in the file, excluding the headers. This index is the only  aspect of SeeSV that may use a significant amount of memory. In testing, the scan of a 5 million row file (2.3GB) took around 4 seconds and produced an index using 18MB of memory. The index enables a constant-time seek to any part of a file by row number.\n3. As a consequence of step 2, the row count is obtained and made available as a property of the DelimitedFile object.\n4. File size is also made available through a property.\n\nThe DelimitedFile class encapsulates all of the functionality. It is implemented as a context manager, allowing with the `with` block to ensure that the source file is closed and memory released when done with the file. Use of the context manager interface is optional, and a developer can choose the manual route of calling `.open()` and `.close()`.\n\n\n\n## Development\n\nSeeSV uses [Poetry](https://python-poetry.org/) to build and publish. Poetry's excellent dependency management feature is not needed, since SeeSV has no dependencies. However, Poetry comes in handy for managing the development environment.\n\nTo get started with working on the code, first get Poetry installed, then follow these steps:\n\n**Create a new virtual environment for the project (or use the currently activated one)**\n\n```shell\npoetry shell\n```\n\n**Get the development dependencies installed** (pytest, flake8, etc)\n\n```shell\npoetry install\n```\n\nThis command also installs the seesv library into the virtual environment's site_packages.\n\n**Build the code**\n\n```shell\npoetry build\n```\n\nThis generates both an sdist(tar.gz file) and a Wheel file that can then be installed using Pip.\n\n\n\n## Examples\n\n\n\n**Example 1:** a file with the context manager interface, assuming that the file has a header line:\n\n```python\nfrom seesv import DelimitedFile\n...\n\nwith DelimitedFile('/path/to/test.csv') as csv_file:\n    ...\n    # Array of column headers is available as csv_file.header\n    \n    # Get 1,000 rows starting from row 25,000\n    for row in csv_file.get_rows(25000, 1000):\n        # work with row\n```\n\n\n\n**Example 2:** Similar to Example 1, except the file contains two extra metadata lines at the top before the column headers that we want to skip:\n\n```python\nwith DelimitedFile('/path/to/test.csv', skip_rows=2) as csv_file:\n    ...\n    # Get 1,000 rows starting from row 25,000\n    for row in csv_file.get_rows(25000, 1000):\n        # work with row\n```\n\n\n\n**Example 3:** The file does not contain a header row, so we just want access to the data:\n\n```python\nwith DelimitedFile('/path/to/test.csv', has_header=False) as csv_file:\n    ...\n    # csv_file.header is not populated\n    \n    # Get 1,000 rows starting from row 25,000\n    for row in csv_file.get_rows(25000, 1000):\n        # work with row\n```\n\n\n\n**Example 4:** We don't want to use the context manager interface:\n\n```python\ncsv_file = DelimitedFile('/path/to/test.csv')\ncsv_file.open()\n...\ncsv_file.close()\n```\n\n\n\n**Example 5:** We just want to get a single row from the file:\n\n```python\nwith DelimitedFile('/path/to/test.csv') as csv_file:\n    row = csv_file.get_row(1500)\n    \n    # Get the last row of the file\n    row = csv_file.get_row(csv_file.rowCount)\n```\n\n\n\n**Example 6:**  Get all rows from a given point till the end of the file:\n\n```python\nwith DelimitedFile('/path/to/test.csv') as csv_file:\n    for row in csv_file.get_rows(1500):\n        ...\n    # Get last 100 rows in the file\n    for row in csv_file.get_rows(csv_file.rowCount - 100):\n        ...\n```\n\n\n\n## Roadmap\n\nThe following are some of the features that are coming:\n\n- Automatically detect column data types\n- Allow user to supply column schema.\n- Support for file formats other than CSV:\n  - Tab-separated\n  - Pipe-delimited\n  - JSON (?)\n  - Compressed files (e.g. myfile.csv.gz)\n- Auto-detect which line contains headers (e.g. ignore any metadata rows at the top of the file)\n- Filters\n- SQL Queries\n- Projections - get specified columns instead of all columns",
    'author': 'David Alexis',
    'author_email': 'dalexis@gmail.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/davealexis/pyseesv',
    'packages': packages,
    'package_data': package_data,
    'python_requires': '>=3.9,<4.0',
}


setup(**setup_kwargs)
